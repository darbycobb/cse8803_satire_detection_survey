{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_csv('unclean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>Heading_Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Here Are 10 Babylon Bee Jokes Explained (Just ...</td>\n",
       "      <td>From the Atlantic to the Pacific a lot of peop...</td>\n",
       "      <td>satire</td>\n",
       "      <td>Here Are 10 Babylon Bee Jokes Explained (Just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pete Buttigieg Says He Cannot Come Into Work A...</td>\n",
       "      <td>WASHINGTON D.C.—With catastrophic labor shorta...</td>\n",
       "      <td>satire</td>\n",
       "      <td>Pete Buttigieg Says He Cannot Come Into Work A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Instead Of Kryptonite, New LGBTQ+ Superman Wil...</td>\n",
       "      <td>BURBANK CA—The brilliant and courageous writer...</td>\n",
       "      <td>satire</td>\n",
       "      <td>Instead Of Kryptonite, New LGBTQ+ Superman Wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Bernie Retires As His Vision Of Making The U.S...</td>\n",
       "      <td>BURLINGTON VT—Bernie Sanders has retired as a ...</td>\n",
       "      <td>satire</td>\n",
       "      <td>Bernie Retires As His Vision Of Making The U.S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Katie Couric Admits She Edited Interview To Re...</td>\n",
       "      <td>U.S.—Katie Couric has admitted to editing an i...</td>\n",
       "      <td>satire</td>\n",
       "      <td>Katie Couric Admits She Edited Interview To Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59782</td>\n",
       "      <td>U.S. Flying Bombers Above Disputed South China...</td>\n",
       "      <td>The U. S. military confirmed a military exerci...</td>\n",
       "      <td>real</td>\n",
       "      <td>U.S. Flying Bombers Above Disputed South China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59783</td>\n",
       "      <td>Battle over Scalia’s replacement already spill...</td>\n",
       "      <td>Conservative and liberal advocacy groups are g...</td>\n",
       "      <td>real</td>\n",
       "      <td>Battle over Scalia’s replacement already spill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59784</td>\n",
       "      <td>Trump administration to review goal of world w...</td>\n",
       "      <td>WASHINGTON (Reuters) - The Trump administratio...</td>\n",
       "      <td>real</td>\n",
       "      <td>Trump administration to review goal of world w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59785</td>\n",
       "      <td>Strong organization helps Cruz dominate Colora...</td>\n",
       "      <td>Colorado Springs, Colorado (CNN) Ted Cruz on S...</td>\n",
       "      <td>real</td>\n",
       "      <td>Strong organization helps Cruz dominate Colora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59786</td>\n",
       "      <td>As Brexit deal takes shape, Juncker to meet MEPs</td>\n",
       "      <td>BRUSSELS (Reuters) - The European Commission a...</td>\n",
       "      <td>real</td>\n",
       "      <td>As Brexit deal takes shape, Juncker to meet ME...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59787 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Heading  \\\n",
       "0      Here Are 10 Babylon Bee Jokes Explained (Just ...   \n",
       "1      Pete Buttigieg Says He Cannot Come Into Work A...   \n",
       "2      Instead Of Kryptonite, New LGBTQ+ Superman Wil...   \n",
       "3      Bernie Retires As His Vision Of Making The U.S...   \n",
       "4      Katie Couric Admits She Edited Interview To Re...   \n",
       "...                                                  ...   \n",
       "59782  U.S. Flying Bombers Above Disputed South China...   \n",
       "59783  Battle over Scalia’s replacement already spill...   \n",
       "59784  Trump administration to review goal of world w...   \n",
       "59785  Strong organization helps Cruz dominate Colora...   \n",
       "59786   As Brexit deal takes shape, Juncker to meet MEPs   \n",
       "\n",
       "                                                    Body   label  \\\n",
       "0      From the Atlantic to the Pacific a lot of peop...  satire   \n",
       "1      WASHINGTON D.C.—With catastrophic labor shorta...  satire   \n",
       "2      BURBANK CA—The brilliant and courageous writer...  satire   \n",
       "3      BURLINGTON VT—Bernie Sanders has retired as a ...  satire   \n",
       "4      U.S.—Katie Couric has admitted to editing an i...  satire   \n",
       "...                                                  ...     ...   \n",
       "59782  The U. S. military confirmed a military exerci...    real   \n",
       "59783  Conservative and liberal advocacy groups are g...    real   \n",
       "59784  WASHINGTON (Reuters) - The Trump administratio...    real   \n",
       "59785  Colorado Springs, Colorado (CNN) Ted Cruz on S...    real   \n",
       "59786  BRUSSELS (Reuters) - The European Commission a...    real   \n",
       "\n",
       "                                            Heading_Body  \n",
       "0      Here Are 10 Babylon Bee Jokes Explained (Just ...  \n",
       "1      Pete Buttigieg Says He Cannot Come Into Work A...  \n",
       "2      Instead Of Kryptonite, New LGBTQ+ Superman Wil...  \n",
       "3      Bernie Retires As His Vision Of Making The U.S...  \n",
       "4      Katie Couric Admits She Edited Interview To Re...  \n",
       "...                                                  ...  \n",
       "59782  U.S. Flying Bombers Above Disputed South China...  \n",
       "59783  Battle over Scalia’s replacement already spill...  \n",
       "59784  Trump administration to review goal of world w...  \n",
       "59785  Strong organization helps Cruz dominate Colora...  \n",
       "59786  As Brexit deal takes shape, Juncker to meet ME...  \n",
       "\n",
       "[59787 rows x 4 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Convert to lowercase\n",
    "combined = combined.applymap(lambda s: str(s).lower())\n",
    "\n",
    "# Fix Contractions\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "contraction_dict_2 = {\"ain’t\": \"is not\", \"aren’t\": \"are not\",\"can’t\": \"cannot\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\", \"didn’t\": \"did not\",  \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he would\",\"he’ll\": \"he will\", \"he’s\": \"he is\", \"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\",  \"I’d\": \"I would\", \"I’d’ve\": \"I would have\", \"I’ll\": \"I will\", \"I’ll’ve\": \"I will have\",\"I’m\": \"I am\", \"I’ve\": \"I have\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\", \"i’ll\": \"i will\",  \"i’ll've\": \"i will have\",\"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\", \"it’d’ve\": \"it would have\", \"it’ll\": \"it will\", \"it’ll’ve\": \"it will have\",\"it’s\": \"it is\", \"let’s\": \"let us\", \"ma’am\": \"madam\", \"mayn’t\": \"may not\", \"might’ve\": \"might have\",\"mightn’t\": \"might not\",\"mightn’t’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\", \"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\",\"o’clock\": \"of the clock\", \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\", \"shan’t\": \"shall not\", \"sha’n’t\": \"shall not\", \"shan’t’ve\": \"shall not have\", \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\", \"she’ll’ve\": \"she will have\", \"she’s\": \"she is\", \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\", \"so’ve\": \"so have\",\"so’s\": \"so as\", \"this’s\": \"this is\",\"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\", \"there’d’ve\": \"there would have\", \"there’s\": \"there is\", \"here’s\": \"here is\",\"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\", \"they’ll’ve\": \"they will have\", \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\", \"we’d’ve\": \"we would have\", \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\", \"what’ll’ve\": \"what will have\", \"what’re\": \"what are\",  \"what’s\": \"what is\", \"what’ve\": \"what have\", \"when’s\": \"when is\", \"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\", \"who’ll’ve\": \"who will have\", \"who’s\": \"who is\", \"who’ve\": \"who have\", \"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\", \"won’t\": \"will not\", \"won’t’ve\": \"will not have\", \"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\",\"y’all’d’ve\": \"you all would have\",\"y’all’re\": \"you all are\",\"y’all’ve\": \"you all have\",\"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\", \"you’re\": \"you are\", \"you’ve\": \"you have\"}\n",
    "\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "contractions_2, contractions_re_2 = _get_contractions(contraction_dict_2)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace_1(match):\n",
    "        return contractions[match.group(0)]\n",
    "    def replace_2(match):\n",
    "        return contractions_2[match.group(0)]\n",
    "    clean_1 = contractions_re.sub(replace_1, text)\n",
    "    clean_2 = contractions_re_2.sub(replace_2, clean_1)\n",
    "    return clean_2\n",
    "combined['Heading_Body'] = combined['Heading_Body'].apply(replace_contractions)\n",
    "combined['Heading'] = combined['Heading'].apply(replace_contractions)\n",
    "combined['Body'] = combined['Body'].apply(replace_contractions)\n",
    "\n",
    "import string\n",
    "# Remove Puncuation\n",
    "def remove_punc(s):\n",
    "    punc_dict = {key: ' ' for key in string.punctuation}\n",
    "    punc_dict['“'] = None\n",
    "    punc_dict['—'] = ' '\n",
    "    punc_dict['’'] = ' '\n",
    "    punc_dict['.'] = '.'\n",
    "    punc_dict['.'] = '?'\n",
    "    punc_dict['.'] = '!'\n",
    "    table = str.maketrans(punc_dict)  # OR {key: None for key in string.punctuation}\n",
    "    new_s = s.str.translate(table)\n",
    "    return new_s\n",
    "combined = combined.apply(remove_punc, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>Heading_Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>here are 10 babylon bee jokes explained (just ...</td>\n",
       "      <td>from the atlantic to the pacific a lot of peop...</td>\n",
       "      <td>satire</td>\n",
       "      <td>here are 10 babylon bee jokes explained (just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pete buttigieg says he cannot come into work a...</td>\n",
       "      <td>washington d.c.—with catastrophic labor shorta...</td>\n",
       "      <td>satire</td>\n",
       "      <td>pete buttigieg says he cannot come into work a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>instead of kryptonite, new lgbtq+ superman wil...</td>\n",
       "      <td>burbank ca—the brilliant and courageous writer...</td>\n",
       "      <td>satire</td>\n",
       "      <td>instead of kryptonite, new lgbtq+ superman wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie retires as his vision of making the u.s...</td>\n",
       "      <td>burlington vt—bernie sanders has retired as a ...</td>\n",
       "      <td>satire</td>\n",
       "      <td>bernie retires as his vision of making the u.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>katie couric admits she edited interview to re...</td>\n",
       "      <td>u.s.—katie couric has admitted to editing an i...</td>\n",
       "      <td>satire</td>\n",
       "      <td>katie couric admits she edited interview to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59782</td>\n",
       "      <td>u.s. flying bombers above disputed south china...</td>\n",
       "      <td>the u. s. military confirmed a military exerci...</td>\n",
       "      <td>real</td>\n",
       "      <td>u.s. flying bombers above disputed south china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59783</td>\n",
       "      <td>battle over scalia’s replacement already spill...</td>\n",
       "      <td>conservative and liberal advocacy groups are g...</td>\n",
       "      <td>real</td>\n",
       "      <td>battle over scalia’s replacement already spill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59784</td>\n",
       "      <td>trump administration to review goal of world w...</td>\n",
       "      <td>washington (reuters) - the trump administratio...</td>\n",
       "      <td>real</td>\n",
       "      <td>trump administration to review goal of world w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59785</td>\n",
       "      <td>strong organization helps cruz dominate colora...</td>\n",
       "      <td>colorado springs, colorado (cnn) ted cruz on s...</td>\n",
       "      <td>real</td>\n",
       "      <td>strong organization helps cruz dominate colora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59786</td>\n",
       "      <td>as brexit deal takes shape, juncker to meet meps</td>\n",
       "      <td>brussels (reuters) - the european commission a...</td>\n",
       "      <td>real</td>\n",
       "      <td>as brexit deal takes shape, juncker to meet me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59787 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Heading  \\\n",
       "0      here are 10 babylon bee jokes explained (just ...   \n",
       "1      pete buttigieg says he cannot come into work a...   \n",
       "2      instead of kryptonite, new lgbtq+ superman wil...   \n",
       "3      bernie retires as his vision of making the u.s...   \n",
       "4      katie couric admits she edited interview to re...   \n",
       "...                                                  ...   \n",
       "59782  u.s. flying bombers above disputed south china...   \n",
       "59783  battle over scalia’s replacement already spill...   \n",
       "59784  trump administration to review goal of world w...   \n",
       "59785  strong organization helps cruz dominate colora...   \n",
       "59786   as brexit deal takes shape, juncker to meet meps   \n",
       "\n",
       "                                                    Body   label  \\\n",
       "0      from the atlantic to the pacific a lot of peop...  satire   \n",
       "1      washington d.c.—with catastrophic labor shorta...  satire   \n",
       "2      burbank ca—the brilliant and courageous writer...  satire   \n",
       "3      burlington vt—bernie sanders has retired as a ...  satire   \n",
       "4      u.s.—katie couric has admitted to editing an i...  satire   \n",
       "...                                                  ...     ...   \n",
       "59782  the u. s. military confirmed a military exerci...    real   \n",
       "59783  conservative and liberal advocacy groups are g...    real   \n",
       "59784  washington (reuters) - the trump administratio...    real   \n",
       "59785  colorado springs, colorado (cnn) ted cruz on s...    real   \n",
       "59786  brussels (reuters) - the european commission a...    real   \n",
       "\n",
       "                                            Heading_Body  \n",
       "0      here are 10 babylon bee jokes explained (just ...  \n",
       "1      pete buttigieg says he cannot come into work a...  \n",
       "2      instead of kryptonite, new lgbtq+ superman wil...  \n",
       "3      bernie retires as his vision of making the u.s...  \n",
       "4      katie couric admits she edited interview to re...  \n",
       "...                                                  ...  \n",
       "59782  u.s. flying bombers above disputed south china...  \n",
       "59783  battle over scalia’s replacement already spill...  \n",
       "59784  trump administration to review goal of world w...  \n",
       "59785  strong organization helps cruz dominate colora...  \n",
       "59786  as brexit deal takes shape, juncker to meet me...  \n",
       "\n",
       "[59787 rows x 4 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokens = combined.copy()\n",
    "tokens['token_heading'] = combined['Heading'].apply(lambda row: nltk.word_tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['token_body'] = combined['Body'].apply(lambda row: nltk.word_tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['token_heading_body'] = combined['Heading_Body'].apply(lambda row: nltk.word_tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['heading_len'] = tokens['token_heading'].apply(lambda row: len(row))\n",
    "tokens['body_len'] = tokens['token_body'].apply(lambda row: len(row))\n",
    "tokens['heading_body_len'] = tokens['token_heading_body'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>Heading_Body</th>\n",
       "      <th>token_heading</th>\n",
       "      <th>token_body</th>\n",
       "      <th>token_heading_body</th>\n",
       "      <th>heading_len</th>\n",
       "      <th>body_len</th>\n",
       "      <th>heading_body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>here are 10 babylon bee jokes explained (just ...</td>\n",
       "      <td>from the atlantic to the pacific a lot of peop...</td>\n",
       "      <td>satire</td>\n",
       "      <td>here are 10 babylon bee jokes explained (just ...</td>\n",
       "      <td>[here, are, 10, babylon, bee, jokes, explained...</td>\n",
       "      <td>[from, the, atlantic, to, the, pacific, a, lot...</td>\n",
       "      <td>[here, are, 10, babylon, bee, jokes, explained...</td>\n",
       "      <td>17</td>\n",
       "      <td>459</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pete buttigieg says he cannot come into work a...</td>\n",
       "      <td>washington d.c.—with catastrophic labor shorta...</td>\n",
       "      <td>satire</td>\n",
       "      <td>pete buttigieg says he cannot come into work a...</td>\n",
       "      <td>[pete, buttigieg, says, he, can, not, come, in...</td>\n",
       "      <td>[washington, d.c.—with, catastrophic, labor, s...</td>\n",
       "      <td>[pete, buttigieg, says, he, can, not, come, in...</td>\n",
       "      <td>15</td>\n",
       "      <td>245</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>instead of kryptonite, new lgbtq+ superman wil...</td>\n",
       "      <td>burbank ca—the brilliant and courageous writer...</td>\n",
       "      <td>satire</td>\n",
       "      <td>instead of kryptonite, new lgbtq+ superman wil...</td>\n",
       "      <td>[instead, of, kryptonite, ,, new, lgbtq+, supe...</td>\n",
       "      <td>[burbank, ca—the, brilliant, and, courageous, ...</td>\n",
       "      <td>[instead, of, kryptonite, ,, new, lgbtq+, supe...</td>\n",
       "      <td>15</td>\n",
       "      <td>203</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie retires as his vision of making the u.s...</td>\n",
       "      <td>burlington vt—bernie sanders has retired as a ...</td>\n",
       "      <td>satire</td>\n",
       "      <td>bernie retires as his vision of making the u.s...</td>\n",
       "      <td>[bernie, retires, as, his, vision, of, making,...</td>\n",
       "      <td>[burlington, vt—bernie, sanders, has, retired,...</td>\n",
       "      <td>[bernie, retires, as, his, vision, of, making,...</td>\n",
       "      <td>16</td>\n",
       "      <td>196</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>katie couric admits she edited interview to re...</td>\n",
       "      <td>u.s.—katie couric has admitted to editing an i...</td>\n",
       "      <td>satire</td>\n",
       "      <td>katie couric admits she edited interview to re...</td>\n",
       "      <td>[katie, couric, admits, she, edited, interview...</td>\n",
       "      <td>[u.s.—katie, couric, has, admitted, to, editin...</td>\n",
       "      <td>[katie, couric, admits, she, edited, interview...</td>\n",
       "      <td>18</td>\n",
       "      <td>257</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59782</td>\n",
       "      <td>u.s. flying bombers above disputed south china...</td>\n",
       "      <td>the u. s. military confirmed a military exerci...</td>\n",
       "      <td>real</td>\n",
       "      <td>u.s. flying bombers above disputed south china...</td>\n",
       "      <td>[u.s., flying, bombers, above, disputed, south...</td>\n",
       "      <td>[the, u., s., military, confirmed, a, military...</td>\n",
       "      <td>[u.s., flying, bombers, above, disputed, south...</td>\n",
       "      <td>13</td>\n",
       "      <td>601</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59783</td>\n",
       "      <td>battle over scalia’s replacement already spill...</td>\n",
       "      <td>conservative and liberal advocacy groups are g...</td>\n",
       "      <td>real</td>\n",
       "      <td>battle over scalia’s replacement already spill...</td>\n",
       "      <td>[battle, over, scalia, ’, s, replacement, alre...</td>\n",
       "      <td>[conservative, and, liberal, advocacy, groups,...</td>\n",
       "      <td>[battle, over, scalia, ’, s, replacement, alre...</td>\n",
       "      <td>11</td>\n",
       "      <td>1300</td>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59784</td>\n",
       "      <td>trump administration to review goal of world w...</td>\n",
       "      <td>washington (reuters) - the trump administratio...</td>\n",
       "      <td>real</td>\n",
       "      <td>trump administration to review goal of world w...</td>\n",
       "      <td>[trump, administration, to, review, goal, of, ...</td>\n",
       "      <td>[washington, (, reuters, ), -, the, trump, adm...</td>\n",
       "      <td>[trump, administration, to, review, goal, of, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>716</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59785</td>\n",
       "      <td>strong organization helps cruz dominate colora...</td>\n",
       "      <td>colorado springs, colorado (cnn) ted cruz on s...</td>\n",
       "      <td>real</td>\n",
       "      <td>strong organization helps cruz dominate colora...</td>\n",
       "      <td>[strong, organization, helps, cruz, dominate, ...</td>\n",
       "      <td>[colorado, springs, ,, colorado, (, cnn, ), te...</td>\n",
       "      <td>[strong, organization, helps, cruz, dominate, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2345</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59786</td>\n",
       "      <td>as brexit deal takes shape, juncker to meet meps</td>\n",
       "      <td>brussels (reuters) - the european commission a...</td>\n",
       "      <td>real</td>\n",
       "      <td>as brexit deal takes shape, juncker to meet me...</td>\n",
       "      <td>[as, brexit, deal, takes, shape, ,, juncker, t...</td>\n",
       "      <td>[brussels, (, reuters, ), -, the, european, co...</td>\n",
       "      <td>[as, brexit, deal, takes, shape, ,, juncker, t...</td>\n",
       "      <td>10</td>\n",
       "      <td>876</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59787 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Heading  \\\n",
       "0      here are 10 babylon bee jokes explained (just ...   \n",
       "1      pete buttigieg says he cannot come into work a...   \n",
       "2      instead of kryptonite, new lgbtq+ superman wil...   \n",
       "3      bernie retires as his vision of making the u.s...   \n",
       "4      katie couric admits she edited interview to re...   \n",
       "...                                                  ...   \n",
       "59782  u.s. flying bombers above disputed south china...   \n",
       "59783  battle over scalia’s replacement already spill...   \n",
       "59784  trump administration to review goal of world w...   \n",
       "59785  strong organization helps cruz dominate colora...   \n",
       "59786   as brexit deal takes shape, juncker to meet meps   \n",
       "\n",
       "                                                    Body   label  \\\n",
       "0      from the atlantic to the pacific a lot of peop...  satire   \n",
       "1      washington d.c.—with catastrophic labor shorta...  satire   \n",
       "2      burbank ca—the brilliant and courageous writer...  satire   \n",
       "3      burlington vt—bernie sanders has retired as a ...  satire   \n",
       "4      u.s.—katie couric has admitted to editing an i...  satire   \n",
       "...                                                  ...     ...   \n",
       "59782  the u. s. military confirmed a military exerci...    real   \n",
       "59783  conservative and liberal advocacy groups are g...    real   \n",
       "59784  washington (reuters) - the trump administratio...    real   \n",
       "59785  colorado springs, colorado (cnn) ted cruz on s...    real   \n",
       "59786  brussels (reuters) - the european commission a...    real   \n",
       "\n",
       "                                            Heading_Body  \\\n",
       "0      here are 10 babylon bee jokes explained (just ...   \n",
       "1      pete buttigieg says he cannot come into work a...   \n",
       "2      instead of kryptonite, new lgbtq+ superman wil...   \n",
       "3      bernie retires as his vision of making the u.s...   \n",
       "4      katie couric admits she edited interview to re...   \n",
       "...                                                  ...   \n",
       "59782  u.s. flying bombers above disputed south china...   \n",
       "59783  battle over scalia’s replacement already spill...   \n",
       "59784  trump administration to review goal of world w...   \n",
       "59785  strong organization helps cruz dominate colora...   \n",
       "59786  as brexit deal takes shape, juncker to meet me...   \n",
       "\n",
       "                                           token_heading  \\\n",
       "0      [here, are, 10, babylon, bee, jokes, explained...   \n",
       "1      [pete, buttigieg, says, he, can, not, come, in...   \n",
       "2      [instead, of, kryptonite, ,, new, lgbtq+, supe...   \n",
       "3      [bernie, retires, as, his, vision, of, making,...   \n",
       "4      [katie, couric, admits, she, edited, interview...   \n",
       "...                                                  ...   \n",
       "59782  [u.s., flying, bombers, above, disputed, south...   \n",
       "59783  [battle, over, scalia, ’, s, replacement, alre...   \n",
       "59784  [trump, administration, to, review, goal, of, ...   \n",
       "59785  [strong, organization, helps, cruz, dominate, ...   \n",
       "59786  [as, brexit, deal, takes, shape, ,, juncker, t...   \n",
       "\n",
       "                                              token_body  \\\n",
       "0      [from, the, atlantic, to, the, pacific, a, lot...   \n",
       "1      [washington, d.c.—with, catastrophic, labor, s...   \n",
       "2      [burbank, ca—the, brilliant, and, courageous, ...   \n",
       "3      [burlington, vt—bernie, sanders, has, retired,...   \n",
       "4      [u.s.—katie, couric, has, admitted, to, editin...   \n",
       "...                                                  ...   \n",
       "59782  [the, u., s., military, confirmed, a, military...   \n",
       "59783  [conservative, and, liberal, advocacy, groups,...   \n",
       "59784  [washington, (, reuters, ), -, the, trump, adm...   \n",
       "59785  [colorado, springs, ,, colorado, (, cnn, ), te...   \n",
       "59786  [brussels, (, reuters, ), -, the, european, co...   \n",
       "\n",
       "                                      token_heading_body  heading_len  \\\n",
       "0      [here, are, 10, babylon, bee, jokes, explained...           17   \n",
       "1      [pete, buttigieg, says, he, can, not, come, in...           15   \n",
       "2      [instead, of, kryptonite, ,, new, lgbtq+, supe...           15   \n",
       "3      [bernie, retires, as, his, vision, of, making,...           16   \n",
       "4      [katie, couric, admits, she, edited, interview...           18   \n",
       "...                                                  ...          ...   \n",
       "59782  [u.s., flying, bombers, above, disputed, south...           13   \n",
       "59783  [battle, over, scalia, ’, s, replacement, alre...           11   \n",
       "59784  [trump, administration, to, review, goal, of, ...           12   \n",
       "59785  [strong, organization, helps, cruz, dominate, ...            8   \n",
       "59786  [as, brexit, deal, takes, shape, ,, juncker, t...           10   \n",
       "\n",
       "       body_len  heading_body_len  \n",
       "0           459               476  \n",
       "1           245               260  \n",
       "2           203               218  \n",
       "3           196               212  \n",
       "4           257               275  \n",
       "...         ...               ...  \n",
       "59782       601               614  \n",
       "59783      1300              1311  \n",
       "59784       716               728  \n",
       "59785      2345              2353  \n",
       "59786       876               886  \n",
       "\n",
       "[59787 rows x 10 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59787.000000\n",
       "mean       500.620770\n",
       "std        598.611684\n",
       "min          1.000000\n",
       "25%        204.000000\n",
       "50%        328.000000\n",
       "75%        578.000000\n",
       "max      19837.000000\n",
       "Name: body_len, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['body_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    201\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['body_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59787.000000\n",
       "mean        13.362838\n",
       "std          5.124816\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         13.000000\n",
       "75%         16.000000\n",
       "max         68.000000\n",
       "Name: heading_len, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['heading_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['heading_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "satire = tokens[tokens.label == 'satire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean        11.625571\n",
       "std          4.284775\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         11.000000\n",
       "75%         14.000000\n",
       "max         67.000000\n",
       "Name: heading_len, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire['heading_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire['heading_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean       241.889357\n",
       "std        150.909676\n",
       "min          1.000000\n",
       "25%        181.000000\n",
       "50%        217.000000\n",
       "75%        264.000000\n",
       "max       8514.000000\n",
       "Name: body_len, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire['body_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    198\n",
       "1    201\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire['body_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = tokens[tokens.label == 'real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean        11.222540\n",
       "std          2.769443\n",
       "min          3.000000\n",
       "25%          9.000000\n",
       "50%         11.000000\n",
       "75%         13.000000\n",
       "max         30.000000\n",
       "Name: heading_len, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['heading_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['heading_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean       613.114356\n",
       "std        592.724712\n",
       "min          7.000000\n",
       "25%        252.000000\n",
       "50%        452.000000\n",
       "75%        835.000000\n",
       "max      13174.000000\n",
       "Name: body_len, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['body_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    74\n",
       "1    83\n",
       "2    91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['body_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = tokens[tokens.label == 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean        14.262984\n",
       "std          5.162041\n",
       "min          1.000000\n",
       "25%         11.000000\n",
       "50%         14.000000\n",
       "75%         17.000000\n",
       "max         61.000000\n",
       "Name: heading_len, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['heading_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['heading_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean       553.858197\n",
       "std        681.165531\n",
       "min          1.000000\n",
       "25%        253.000000\n",
       "50%        399.000000\n",
       "75%        611.000000\n",
       "max      18537.000000\n",
       "Name: body_len, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['body_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    378\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['body_len'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = combined.copy()\n",
    "sentences['body_sentences'] = sentences['Body'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences['num_sentences'] = sentences['body_sentences'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59787.000000\n",
       "mean        19.443073\n",
       "std         27.904780\n",
       "min          1.000000\n",
       "25%          5.000000\n",
       "50%         11.000000\n",
       "75%         22.000000\n",
       "max        930.000000\n",
       "Name: num_sentences, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['num_sentences'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['num_sentences'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_sentences = sentences[sentences.label=='real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean        30.643936\n",
       "std         34.661338\n",
       "min          1.000000\n",
       "25%         11.000000\n",
       "50%         20.000000\n",
       "75%         39.000000\n",
       "max        809.000000\n",
       "Name: num_sentences, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_sentences['num_sentences'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_sentences['num_sentences'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_sentences = sentences[sentences.label=='fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean        20.368408\n",
       "std         28.506518\n",
       "min          1.000000\n",
       "25%          8.000000\n",
       "50%         14.000000\n",
       "75%         23.000000\n",
       "max        930.000000\n",
       "Name: num_sentences, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_sentences['num_sentences'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_sentences['num_sentences'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "satire_sentences = sentences[sentences.label=='satire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19929.000000\n",
       "mean         7.316875\n",
       "std          6.978856\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          6.000000\n",
       "75%          9.000000\n",
       "max        243.000000\n",
       "Name: num_sentences, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire_sentences['num_sentences'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire_sentences['num_sentences'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def words_in_sentences(t):\n",
    "    count = [len(sentence.split()) for sentence in t]\n",
    "    return count\n",
    "\n",
    "sentences['words_in_sent'] = sentences['body_sentences'].apply(lambda x: words_in_sentences(x))\n",
    "real_sentences['words_in_sent'] = real_sentences['body_sentences'].apply(lambda x: words_in_sentences(x))\n",
    "fake_sentences['words_in_sent'] = fake_sentences['body_sentences'].apply(lambda x: words_in_sentences(x))\n",
    "satire_sentences['words_in_sent'] = satire_sentences['body_sentences'].apply(lambda x: words_in_sentences(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in sentences['words_in_sent'] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.162443e+06\n",
       "mean     2.324702e+01\n",
       "std      2.145330e+01\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+01\n",
       "50%      1.900000e+01\n",
       "75%      3.000000e+01\n",
       "max      1.347000e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(flat_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(flat_list).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_word_in_sent = [item for sublist in real_sentences['words_in_sent'] for item in sublist]\n",
    "satire_word_in_sent = [item for sublist in satire_sentences['words_in_sent'] for item in sublist]\n",
    "fake_word_in_sent = [item for sublist in fake_sentences['words_in_sent'] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    610703.000000\n",
       "mean         19.171851\n",
       "std          13.191994\n",
       "min           1.000000\n",
       "25%           9.000000\n",
       "50%          17.000000\n",
       "75%          27.000000\n",
       "max         367.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(real_word_in_sent).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(real_word_in_sent).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    145818.000000\n",
       "mean         31.897262\n",
       "std          32.727136\n",
       "min           1.000000\n",
       "25%          11.000000\n",
       "50%          23.000000\n",
       "75%          41.000000\n",
       "max         585.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(satire_word_in_sent).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(satire_word_in_sent).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    405922.000000\n",
       "mean         26.270638\n",
       "std          24.706755\n",
       "min           1.000000\n",
       "25%          12.000000\n",
       "50%          21.000000\n",
       "75%          33.000000\n",
       "max        1347.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(fake_word_in_sent).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(fake_word_in_sent).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter_all = Counter()\n",
    "for body in combined.Heading_Body:\n",
    "    #t = [word for word in body.split() if not word in stopwords.words()]\n",
    "    counter_all.update(body.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter_fake = Counter()\n",
    "for body in fake.Heading_Body:\n",
    "    counter_fake.update(body.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_real = Counter()\n",
    "for body in real.Heading_Body:\n",
    "    counter_real.update(body.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_satire = Counter()\n",
    "for body in satire.Heading_Body:\n",
    "    counter_satire.update(body.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115451\n"
     ]
    }
   ],
   "source": [
    "print(len(Counter({k: c for k, c in counter_all.items() if c >= 3})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70425\n"
     ]
    }
   ],
   "source": [
    "print(len(Counter({k: c for k, c in counter_fake.items() if c >= 3})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67529\n"
     ]
    }
   ],
   "source": [
    "print(len(Counter({k: c for k, c in counter_real.items() if c >= 3})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50262\n"
     ]
    }
   ],
   "source": [
    "print(len(Counter({k: c for k, c in counter_satire.items() if c >= 3})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1504546),\n",
       " ('to', 777004),\n",
       " ('of', 683687),\n",
       " ('and', 625665),\n",
       " ('a', 616204),\n",
       " ('in', 509132),\n",
       " ('that', 370881),\n",
       " ('is', 315021),\n",
       " ('s', 254894),\n",
       " ('for', 251999),\n",
       " ('on', 245276),\n",
       " ('it', 195796),\n",
       " ('he', 194878),\n",
       " ('with', 177004),\n",
       " ('was', 174668),\n",
       " ('as', 165374),\n",
       " ('not', 164359),\n",
       " ('his', 141815),\n",
       " ('trump', 140474),\n",
       " ('are', 135415)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_all.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 594480),\n",
       " ('to', 306638),\n",
       " ('of', 274709),\n",
       " ('and', 254794),\n",
       " ('a', 220045),\n",
       " ('in', 188156),\n",
       " ('that', 152062),\n",
       " ('is', 140118),\n",
       " ('s', 108984),\n",
       " ('for', 98639),\n",
       " ('on', 84871),\n",
       " ('it', 81432),\n",
       " ('with', 67691),\n",
       " ('as', 65181),\n",
       " ('was', 64936),\n",
       " ('he', 64676),\n",
       " ('trump', 62004),\n",
       " ('not', 60743),\n",
       " ('this', 60679),\n",
       " ('are', 59463)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_fake.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 676694),\n",
       " ('to', 331336),\n",
       " ('of', 295095),\n",
       " ('a', 283478),\n",
       " ('and', 265254),\n",
       " ('in', 249116),\n",
       " ('that', 146287),\n",
       " ('on', 125206),\n",
       " ('is', 115824),\n",
       " ('s', 115656),\n",
       " ('for', 111914),\n",
       " ('he', 88701),\n",
       " ('said', 79713),\n",
       " ('with', 77440),\n",
       " ('it', 77279),\n",
       " ('”', 76866),\n",
       " ('was', 76491),\n",
       " ('as', 70392),\n",
       " ('not', 69208),\n",
       " ('trump', 63206)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_real.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 233372),\n",
       " ('to', 139030),\n",
       " ('of', 113883),\n",
       " ('a', 112681),\n",
       " ('and', 105617),\n",
       " ('that', 72532),\n",
       " ('in', 71860),\n",
       " ('is', 59079),\n",
       " ('he', 41501),\n",
       " ('for', 41446),\n",
       " ('it', 37085),\n",
       " ('on', 35199),\n",
       " ('i', 34833),\n",
       " ('not', 34408),\n",
       " ('his', 33405),\n",
       " ('was', 33241),\n",
       " ('with', 31873),\n",
       " ('s', 30254),\n",
       " ('as', 29801),\n",
       " ('have', 26952)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_satire.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/darbycobb/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_all_stop = {k : c for k,c in counter_all.items() if not k in stopwords.words()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_fake_stop = {k : c for k,c in counter_fake.items() if not k in stopwords.words()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_real_stop = {k : c for k,c in counter_real.items() if not k in stopwords.words()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_satire_stop = {k : c for k,c in counter_satire.items() if k not in stopwords.words()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 20798),\n",
       " ('trump', 15264),\n",
       " ('would', 13356),\n",
       " ('like', 11931),\n",
       " ('new', 11205),\n",
       " ('time', 10414),\n",
       " ('people', 9608),\n",
       " ('president', 7905),\n",
       " ('get', 7863),\n",
       " ('could', 7485)]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(counter_satire_stop).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 79713),\n",
       " ('”', 76866),\n",
       " ('trump', 63206),\n",
       " ('would', 37826),\n",
       " ('mr.', 36817),\n",
       " ('president', 28395),\n",
       " ('new', 28298),\n",
       " ('u.s.', 27950),\n",
       " ('said.', 25850),\n",
       " ('people', 22553)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(counter_real_stop).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 62004),\n",
       " ('people', 25746),\n",
       " ('would', 25705),\n",
       " ('clinton', 25458),\n",
       " ('said', 22668),\n",
       " ('president', 20709),\n",
       " ('us', 19486),\n",
       " ('hillary', 19330),\n",
       " ('like', 17805),\n",
       " ('new', 16686)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(counter_fake_stop).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
